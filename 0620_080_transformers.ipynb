{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e7abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no keyword, location\n",
    "# preprocess & train - transformers - Electra\n",
    "# 分割 dataset - train + validation\n",
    "\n",
    "# ref: https://www.kaggle.com/yossawadeepromwong/disaster-and-nondisaster-tweets/comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c15940e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3469d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will use the GPU: GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():  \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('I will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    \n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97ef7b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"./train.csv\")\n",
    "df_test=pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92c9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess(text):\n",
    "\n",
    "    text=text.lower()\n",
    "    # remove hyperlinks\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    text = re.sub(r'http?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    #Replace &amp, &lt, &gt with &,<,> respectively\n",
    "    text=text.replace(r'&amp;?',r'and')\n",
    "    text=text.replace(r'&lt;',r'<')\n",
    "    text=text.replace(r'&gt;',r'>')\n",
    "    #remove hashtag sign\n",
    "    #text=re.sub(r\"#\",\"\",text)   \n",
    "    #remove mentions\n",
    "    text = re.sub(r\"(?:\\@)\\w+\", '', text)\n",
    "    #text=re.sub(r\"@\",\"\",text)\n",
    "    #remove non ascii chars\n",
    "    text=text.encode(\"ascii\",errors=\"ignore\").decode()\n",
    "    #remove some puncts (except . ! ?)\n",
    "    text=re.sub(r'[:\"#$%&\\*+,-/:;<=>@\\\\^_`{|}~]+','',text)\n",
    "    text=re.sub(r'[!]+','!',text)\n",
    "    text=re.sub(r'[?]+','?',text)\n",
    "    text=re.sub(r'[.]+','.',text)\n",
    "    text=re.sub(r\"'\",\"\",text)\n",
    "    text=re.sub(r\"\\(\",\"\",text)\n",
    "    text=re.sub(r\"\\)\",\"\",text)\n",
    "    # Contractions\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"there's\", \"there is\", text)\n",
    "    text = re.sub(r\"We're\", \"We are\", text)\n",
    "    text = re.sub(r\"That's\", \"That is\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"they're\", \"they are\", text)\n",
    "    text = re.sub(r\"Can't\", \"Cannot\", text)\n",
    "    text = re.sub(r\"wasn't\", \"was not\", text)\n",
    "    text = re.sub(r\"don\\x89Ûªt\", \"do not\", text)\n",
    "    text = re.sub(r\"aren't\", \"are not\", text)\n",
    "    text = re.sub(r\"isn't\", \"is not\", text)\n",
    "    text = re.sub(r\"What's\", \"What is\", text)\n",
    "    text = re.sub(r\"haven't\", \"have not\", text)\n",
    "    text = re.sub(r\"hasn't\", \"has not\", text)\n",
    "    text = re.sub(r\"There's\", \"There is\", text)\n",
    "    text = re.sub(r\"He's\", \"He is\", text)\n",
    "    text = re.sub(r\"It's\", \"It is\", text)\n",
    "    text = re.sub(r\"You're\", \"You are\", text)\n",
    "    text = re.sub(r\"I'M\", \"I am\", text)\n",
    "    text = re.sub(r\"shouldn't\", \"should not\", text)\n",
    "    text = re.sub(r\"wouldn't\", \"would not\", text)\n",
    "    text = re.sub(r\"i'm\", \"I am\", text)\n",
    "    text = re.sub(r\"I\\x89Ûªm\", \"I am\", text)\n",
    "    text = re.sub(r\"I'm\", \"I am\", text)\n",
    "    text = re.sub(r\"Isn't\", \"is not\", text)\n",
    "    text = re.sub(r\"Here's\", \"Here is\", text)\n",
    "    text = re.sub(r\"you've\", \"you have\", text)\n",
    "    text = re.sub(r\"you\\x89Ûªve\", \"you have\", text)\n",
    "    text = re.sub(r\"we're\", \"we are\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"couldn't\", \"could not\", text)\n",
    "    text = re.sub(r\"we've\", \"we have\", text)\n",
    "    text = re.sub(r\"it\\x89Ûªs\", \"it is\", text)\n",
    "    text = re.sub(r\"doesn\\x89Ûªt\", \"does not\", text)\n",
    "    text = re.sub(r\"It\\x89Ûªs\", \"It is\", text)\n",
    "    text = re.sub(r\"Here\\x89Ûªs\", \"Here is\", text)\n",
    "    text = re.sub(r\"who's\", \"who is\", text)\n",
    "    text = re.sub(r\"I\\x89Ûªve\", \"I have\", text)\n",
    "    text = re.sub(r\"y'all\", \"you all\", text)\n",
    "    text = re.sub(r\"can\\x89Ûªt\", \"cannot\", text)\n",
    "    text = re.sub(r\"would've\", \"would have\", text)\n",
    "    text = re.sub(r\"it'll\", \"it will\", text)\n",
    "    text = re.sub(r\"we'll\", \"we will\", text)\n",
    "    text = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", text)\n",
    "    text = re.sub(r\"We've\", \"We have\", text)\n",
    "    text = re.sub(r\"he'll\", \"he will\", text)\n",
    "    text = re.sub(r\"Y'all\", \"You all\", text)\n",
    "    text = re.sub(r\"Weren't\", \"Were not\", text)\n",
    "    text = re.sub(r\"Didn't\", \"Did not\", text)\n",
    "    text = re.sub(r\"they'll\", \"they will\", text)\n",
    "    text = re.sub(r\"they'd\", \"they would\", text)\n",
    "    text = re.sub(r\"DON'T\", \"DO NOT\", text)\n",
    "    text = re.sub(r\"That\\x89Ûªs\", \"That is\", text)\n",
    "    text = re.sub(r\"they've\", \"they have\", text)\n",
    "    text = re.sub(r\"i'd\", \"I would\", text)\n",
    "    text = re.sub(r\"should've\", \"should have\", text)\n",
    "    text = re.sub(r\"You\\x89Ûªre\", \"You are\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"Don\\x89Ûªt\", \"Do not\", text)\n",
    "    text = re.sub(r\"we'd\", \"we would\", text)\n",
    "    text = re.sub(r\"i'll\", \"I will\", text)\n",
    "    text = re.sub(r\"weren't\", \"were not\", text)\n",
    "    text = re.sub(r\"They're\", \"They are\", text)\n",
    "    text = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", text)\n",
    "    text = re.sub(r\"you\\x89Ûªll\", \"you will\", text)\n",
    "    text = re.sub(r\"I\\x89Ûªd\", \"I would\", text)\n",
    "    text = re.sub(r\"let's\", \"let us\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"don't\", \"do not\", text)\n",
    "    text = re.sub(r\"you're\", \"you are\", text)\n",
    "    text = re.sub(r\"i've\", \"I have\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"i'll\", \"I will\", text)\n",
    "    text = re.sub(r\"doesn't\", \"does not\", text)\n",
    "    text = re.sub(r\"i'd\", \"I would\", text)\n",
    "    text = re.sub(r\"didn't\", \"did not\", text)\n",
    "    text = re.sub(r\"ain't\", \"am not\", text)\n",
    "    text = re.sub(r\"you'll\", \"you will\", text)\n",
    "    text = re.sub(r\"I've\", \"I have\", text)\n",
    "    text = re.sub(r\"Don't\", \"do not\", text)\n",
    "    text = re.sub(r\"I'll\", \"I will\", text)\n",
    "    text = re.sub(r\"I'd\", \"I would\", text)\n",
    "    text = re.sub(r\"Let's\", \"Let us\", text)\n",
    "    text = re.sub(r\"you'd\", \"You would\", text)\n",
    "    text = re.sub(r\"It's\", \"It is\", text)\n",
    "    text = re.sub(r\"Ain't\", \"am not\", text)\n",
    "    text = re.sub(r\"Haven't\", \"Have not\", text)\n",
    "    text = re.sub(r\"Could've\", \"Could have\", text)\n",
    "    text = re.sub(r\"youve\", \"you have\", text)  \n",
    "    text = re.sub(r\"donå«t\", \"do not\", text)\n",
    "    \n",
    "    \n",
    "    text=\" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(preprocess)\n",
    "df_test['text'] = df_test['text'].apply(preprocess)\n",
    "df_train = df_train[df_train[\"text\"]!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4ac0958",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[[\"text\",\"target\"]]\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36e4f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bd6b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lists of lyrics and their labels.\n",
    "texts = df_train.text.values\n",
    "labels = df_train.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "211d3a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification, AdamW\n",
    "\n",
    "tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-discriminator')\n",
    "model = ElectraForSequenceClassification.from_pretrained('google/electra-base-discriminator',num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51cb4379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to show length of embedding will be helpful to determine maximum length of comments and padding threshold\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_sentence_embeddings_length(text_list, tokenizer):\n",
    "    tokenized_texts = list(map(lambda t: tokenizer.tokenize(t), text_list))\n",
    "    tokenized_texts_len = list(map(lambda t: len(t), tokenized_texts))\n",
    "    fig, ax = plt.subplots(figsize=(8, 5));\n",
    "    ax.hist(tokenized_texts_len, bins=40);\n",
    "    ax.set_xlabel(\"Length of Comment Embeddings\");\n",
    "    ax.set_ylabel(\"Number of Comments\");\n",
    "    return\n",
    "# plot_sentence_embeddings_length(texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2440a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=tokenizer.batch_encode_plus(texts,max_length=64,add_special_tokens=True, return_attention_mask=True,padding='max_length',truncation=True)\n",
    "\n",
    "input_ids=indices[\"input_ids\"]\n",
    "attention_masks=indices[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "482ce9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use 80% for training and 20% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=42, test_size=0.2)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b59f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "validation_labels = torch.tensor(validation_labels, dtype=torch.long)\n",
    "train_masks = torch.tensor(train_masks, dtype=torch.long)\n",
    "validation_masks = torch.tensor(validation_masks, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba5fb8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f81ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments1 = df_test.text.values\n",
    "\n",
    "indices1=tokenizer.batch_encode_plus(comments1,max_length=128,add_special_tokens=True, return_attention_mask=True,padding='max_length',truncation=True)\n",
    "input_ids1=indices1[\"input_ids\"]\n",
    "attention_masks1=indices1[\"attention_mask\"]\n",
    "\n",
    "prediction_inputs1= torch.tensor(input_ids1)\n",
    "prediction_masks1 = torch.tensor(attention_masks1)\n",
    "\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 8\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data1 = TensorDataset(prediction_inputs1, prediction_masks1)\n",
    "prediction_sampler1 = SequentialSampler(prediction_data1)\n",
    "prediction_dataloader1 = DataLoader(prediction_data1, sampler=prediction_sampler1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b7e0c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 5\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, \n",
    "                                            num_training_steps = total_steps)\n",
    "# scheduler = StepLR(optimizer, step_size=1, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0af8ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40591772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fa930e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validation_dataloader, device):\n",
    "    # Validation\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    \n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "\n",
    "    preds=[]\n",
    "    true=[]\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        preds.append(logits)\n",
    "        true.append(label_ids)\n",
    "        # Calculate the accuracy for this batch.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "    \n",
    "    # Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "    flat_predictions = [item for sublist in preds for item in sublist]\n",
    "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "    # Combine the correct labels for each batch into a single list.\n",
    "    flat_true_labels = [item for sublist in true for item in sublist]\n",
    "    \n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(flat_predictions,flat_true_labels))\n",
    "    \n",
    "    return eval_accuracy/nb_eval_steps # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a88753d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, prediction_dataloader1, device):\n",
    "    print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs1)))\n",
    "\n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    predictions = []\n",
    "\n",
    "    # Predict \n",
    "    for batch in prediction_dataloader1:\n",
    "      # Add batch to GPU\n",
    "      batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "      # Unpack the inputs from our dataloader\n",
    "      b_input_ids1, b_input_mask1 = batch\n",
    "\n",
    "      # Telling the model not to compute or store gradients, saving memory and \n",
    "      # speeding up prediction\n",
    "      with torch.no_grad():\n",
    "          # Forward pass, calculate logit predictions\n",
    "          outputs1 = model(b_input_ids1, token_type_ids=None, \n",
    "                          attention_mask=b_input_mask1)\n",
    "\n",
    "      logits1 = outputs1[0]\n",
    "\n",
    "      # Move logits and labels to CPU\n",
    "      logits1 = logits1.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "      # Store predictions and true labels\n",
    "      predictions.append(logits1)\n",
    "\n",
    "    flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "    answer=pd.read_csv('./answer.csv')\n",
    "    ans = answer['target'].values.tolist()\n",
    "\n",
    "    error = 0\n",
    "    for truth, pred in zip(ans, flat_predictions):\n",
    "        error += abs(truth-pred)\n",
    "    accuracy = 1-error/len(ans)\n",
    "    print(f'  Test Accuracy:', accuracy)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7bb1d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    756.    Elapsed: 0:00:18.\n",
      "  Batch   100  of    756.    Elapsed: 0:00:37.\n",
      "  Batch   150  of    756.    Elapsed: 0:00:56.\n",
      "  Batch   200  of    756.    Elapsed: 0:01:14.\n",
      "  Batch   250  of    756.    Elapsed: 0:01:32.\n",
      "  Batch   300  of    756.    Elapsed: 0:01:59.\n",
      "  Batch   350  of    756.    Elapsed: 0:02:26.\n",
      "  Batch   400  of    756.    Elapsed: 0:02:58.\n",
      "  Batch   450  of    756.    Elapsed: 0:03:33.\n",
      "  Batch   500  of    756.    Elapsed: 0:04:09.\n",
      "  Batch   550  of    756.    Elapsed: 0:04:50.\n",
      "  Batch   600  of    756.    Elapsed: 0:05:28.\n",
      "  Batch   650  of    756.    Elapsed: 0:06:10.\n",
      "  Batch   700  of    756.    Elapsed: 0:06:55.\n",
      "  Batch   750  of    756.    Elapsed: 0:07:38.\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epoch took: 0:07:45\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.77\n",
      "  Validation took: 0:00:55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.78       725\n",
      "           1       0.84      0.68      0.75       788\n",
      "\n",
      "    accuracy                           0.77      1513\n",
      "   macro avg       0.77      0.77      0.76      1513\n",
      "weighted avg       0.78      0.77      0.76      1513\n",
      "\n",
      "Predicting labels for 3,263 test sentences...\n",
      "  Test Accuracy: 0.7863928899785473\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    756.    Elapsed: 0:00:32.\n",
      "  Batch   100  of    756.    Elapsed: 0:01:02.\n",
      "  Batch   150  of    756.    Elapsed: 0:01:29.\n",
      "  Batch   200  of    756.    Elapsed: 0:01:50.\n",
      "  Batch   250  of    756.    Elapsed: 0:02:09.\n",
      "  Batch   300  of    756.    Elapsed: 0:02:28.\n",
      "  Batch   350  of    756.    Elapsed: 0:02:47.\n",
      "  Batch   400  of    756.    Elapsed: 0:03:08.\n",
      "  Batch   450  of    756.    Elapsed: 0:03:31.\n",
      "  Batch   500  of    756.    Elapsed: 0:03:53.\n",
      "  Batch   550  of    756.    Elapsed: 0:04:16.\n",
      "  Batch   600  of    756.    Elapsed: 0:04:40.\n",
      "  Batch   650  of    756.    Elapsed: 0:05:05.\n",
      "  Batch   700  of    756.    Elapsed: 0:05:29.\n",
      "  Batch   750  of    756.    Elapsed: 0:05:53.\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epoch took: 0:05:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.76\n",
      "  Validation took: 0:00:27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.78       729\n",
      "           1       0.83      0.68      0.75       784\n",
      "\n",
      "    accuracy                           0.76      1513\n",
      "   macro avg       0.77      0.77      0.76      1513\n",
      "weighted avg       0.77      0.76      0.76      1513\n",
      "\n",
      "Predicting labels for 3,263 test sentences...\n",
      "  Test Accuracy: 0.7805700275819798\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    756.    Elapsed: 0:00:22.\n",
      "  Batch   100  of    756.    Elapsed: 0:00:45.\n",
      "  Batch   150  of    756.    Elapsed: 0:01:08.\n",
      "  Batch   200  of    756.    Elapsed: 0:01:33.\n",
      "  Batch   250  of    756.    Elapsed: 0:01:57.\n",
      "  Batch   300  of    756.    Elapsed: 0:02:22.\n",
      "  Batch   350  of    756.    Elapsed: 0:02:47.\n",
      "  Batch   400  of    756.    Elapsed: 0:03:12.\n",
      "  Batch   450  of    756.    Elapsed: 0:03:37.\n",
      "  Batch   500  of    756.    Elapsed: 0:04:02.\n",
      "  Batch   550  of    756.    Elapsed: 0:04:26.\n",
      "  Batch   600  of    756.    Elapsed: 0:04:48.\n",
      "  Batch   650  of    756.    Elapsed: 0:05:10.\n",
      "  Batch   700  of    756.    Elapsed: 0:05:31.\n",
      "  Batch   750  of    756.    Elapsed: 0:05:52.\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epoch took: 0:05:55\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.81\n",
      "  Validation took: 0:00:26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       865\n",
      "           1       0.78      0.77      0.78       648\n",
      "\n",
      "    accuracy                           0.81      1513\n",
      "   macro avg       0.81      0.80      0.80      1513\n",
      "weighted avg       0.81      0.81      0.81      1513\n",
      "\n",
      "Predicting labels for 3,263 test sentences...\n",
      "  Test Accuracy: 0.8145878026356114\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    756.    Elapsed: 0:00:21.\n",
      "  Batch   100  of    756.    Elapsed: 0:00:43.\n",
      "  Batch   150  of    756.    Elapsed: 0:01:06.\n",
      "  Batch   200  of    756.    Elapsed: 0:01:28.\n",
      "  Batch   250  of    756.    Elapsed: 0:01:50.\n",
      "  Batch   300  of    756.    Elapsed: 0:02:12.\n",
      "  Batch   350  of    756.    Elapsed: 0:02:36.\n",
      "  Batch   400  of    756.    Elapsed: 0:02:59.\n",
      "  Batch   450  of    756.    Elapsed: 0:03:22.\n",
      "  Batch   500  of    756.    Elapsed: 0:03:47.\n",
      "  Batch   550  of    756.    Elapsed: 0:04:10.\n",
      "  Batch   600  of    756.    Elapsed: 0:04:32.\n",
      "  Batch   650  of    756.    Elapsed: 0:04:54.\n",
      "  Batch   700  of    756.    Elapsed: 0:05:16.\n",
      "  Batch   750  of    756.    Elapsed: 0:05:41.\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epoch took: 0:05:44\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80\n",
      "  Validation took: 0:00:27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       846\n",
      "           1       0.78      0.75      0.77       667\n",
      "\n",
      "    accuracy                           0.80      1513\n",
      "   macro avg       0.80      0.79      0.79      1513\n",
      "weighted avg       0.80      0.80      0.80      1513\n",
      "\n",
      "Predicting labels for 3,263 test sentences...\n",
      "  Test Accuracy: 0.8038614771682501\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    756.    Elapsed: 0:00:24.\n",
      "  Batch   100  of    756.    Elapsed: 0:00:48.\n",
      "  Batch   150  of    756.    Elapsed: 0:01:11.\n",
      "  Batch   200  of    756.    Elapsed: 0:01:35.\n",
      "  Batch   250  of    756.    Elapsed: 0:01:59.\n",
      "  Batch   300  of    756.    Elapsed: 0:02:25.\n",
      "  Batch   350  of    756.    Elapsed: 0:02:51.\n",
      "  Batch   400  of    756.    Elapsed: 0:03:16.\n",
      "  Batch   450  of    756.    Elapsed: 0:03:41.\n",
      "  Batch   500  of    756.    Elapsed: 0:04:05.\n",
      "  Batch   550  of    756.    Elapsed: 0:04:29.\n",
      "  Batch   600  of    756.    Elapsed: 0:04:53.\n",
      "  Batch   650  of    756.    Elapsed: 0:05:18.\n",
      "  Batch   700  of    756.    Elapsed: 0:05:42.\n",
      "  Batch   750  of    756.    Elapsed: 0:06:05.\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epoch took: 0:06:08\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80\n",
      "  Validation took: 0:00:28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83       872\n",
      "           1       0.76      0.77      0.76       641\n",
      "\n",
      "    accuracy                           0.80      1513\n",
      "   macro avg       0.79      0.79      0.79      1513\n",
      "weighted avg       0.80      0.80      0.80      1513\n",
      "\n",
      "Predicting labels for 3,263 test sentences...\n",
      "  Test Accuracy: 0.8084584737971192\n",
      "\n",
      "Training complete!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# plotting\n",
    "pic_epoch = []\n",
    "pic_val_accu = []\n",
    "pic_test_accu = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    \n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 100 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # `batch` contains three pytorch tensors: [0]: input ids ,[1]: attention masks,[2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Clear any previously calculated gradients.\n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Evaluate the model on this training batch.\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches \n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0. to prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "    \n",
    "    ##################################################################\n",
    "    val_accu = validation(model, validation_dataloader, device)\n",
    "    test_accu = test(model, prediction_dataloader1, device)\n",
    "    pic_epoch.append(epoch_i+1)\n",
    "    pic_val_accu.append(val_accu)\n",
    "    pic_test_accu.append(test_accu)\n",
    "    \n",
    "      \n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "plt.plot(pic_epoch, pic_val_accu, color = 'blue', marker='o', linestyle = '--', label='Validation')\n",
    "plt.plot(pic_epoch, pic_test_accu, color = 'orange', marker='o', linestyle = '-', label='Test')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.xlabel('Epoch', color = 'red')\n",
    "plt.ylabel('Accuracy', color = 'red')\n",
    "plt.title('Accuracy per epoch', color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.8348145878026356 batch = 8, epoch = 2, lr = 2e-5, eps = 1e-8\n",
    "# 0.816426601287159 batch = 8, epoch = 3, lr = 2e-5, eps = 1e-8\n",
    "# 0.8271529267545203 batch = 8, epoch = 4, lr = 2e-5, eps = 1e-8\n",
    "# 0.8277658596383696 batch = 8, epoch = 2, lr = 2e-5, eps = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eeaabeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_sub=pd.read_csv('./dataset/sample_submission.csv')\n",
    "# submit=pd.DataFrame({'id':sample_sub['id'].values.tolist(),'target':flat_predictions})\n",
    "# submit.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96d85cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submit.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
