{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39e7abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no keyword, location\n",
    "# preprocess & train - transformers - Electra\n",
    "# 分割 dataset - train + validation\n",
    "\n",
    "# ref: https://www.kaggle.com/yossawadeepromwong/disaster-and-nondisaster-tweets/comments\n",
    "# ref: https://www.kaggle.com/gunesevitan/nlp-with-disaster-tweets-eda-cleaning-and-bert#4.-Embeddings-and-Text-Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c15940e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b3469d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# if torch.cuda.is_available():  \n",
    "#     device = torch.device(\"cuda\")\n",
    "#     print('I will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    \n",
    "# else:\n",
    "#     print('No GPU available, using the CPU instead.')\n",
    "#     device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ef7b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"./train.csv\")\n",
    "df_test=pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92c9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "def preprocess(text):\n",
    "\n",
    "    text=text.lower()\n",
    "    # remove hyperlinks\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    text = re.sub(r'http?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    #Replace &amp, &lt, &gt with &,<,> respectively\n",
    "    text=text.replace(r'&amp;?',r'and')\n",
    "    text=text.replace(r'&lt;',r'<')\n",
    "    text=text.replace(r'&gt;',r'>')\n",
    "    #remove hashtag sign\n",
    "    #text=re.sub(r\"#\",\"\",text)   \n",
    "    #remove mentions\n",
    "    text = re.sub(r\"(?:\\@)\\w+\", '', text)\n",
    "    #text=re.sub(r\"@\",\"\",text)\n",
    "    #remove non ascii chars\n",
    "    text=text.encode(\"ascii\",errors=\"ignore\").decode()\n",
    "    #remove some puncts (except . ! ?)\n",
    "    text=re.sub(r'[:\"#$%&\\*+,-/:;<=>@\\\\^_`{|}~]+','',text)\n",
    "    text=re.sub(r'[!]+','!',text)\n",
    "    text=re.sub(r'[?]+','?',text)\n",
    "    text=re.sub(r'[.]+','.',text)\n",
    "    text=re.sub(r\"'\",\"\",text)\n",
    "    text=re.sub(r\"\\(\",\"\",text)\n",
    "    text=re.sub(r\"\\)\",\"\",text)\n",
    "    # Contractions\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"there's\", \"there is\", text)\n",
    "    text = re.sub(r\"We're\", \"We are\", text)\n",
    "    text = re.sub(r\"That's\", \"That is\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"they're\", \"they are\", text)\n",
    "    text = re.sub(r\"Can't\", \"Cannot\", text)\n",
    "    text = re.sub(r\"wasn't\", \"was not\", text)\n",
    "    text = re.sub(r\"don\\x89Ûªt\", \"do not\", text)\n",
    "    text = re.sub(r\"aren't\", \"are not\", text)\n",
    "    text = re.sub(r\"isn't\", \"is not\", text)\n",
    "    text = re.sub(r\"What's\", \"What is\", text)\n",
    "    text = re.sub(r\"haven't\", \"have not\", text)\n",
    "    text = re.sub(r\"hasn't\", \"has not\", text)\n",
    "    text = re.sub(r\"There's\", \"There is\", text)\n",
    "    text = re.sub(r\"He's\", \"He is\", text)\n",
    "    text = re.sub(r\"It's\", \"It is\", text)\n",
    "    text = re.sub(r\"You're\", \"You are\", text)\n",
    "    text = re.sub(r\"I'M\", \"I am\", text)\n",
    "    text = re.sub(r\"shouldn't\", \"should not\", text)\n",
    "    text = re.sub(r\"wouldn't\", \"would not\", text)\n",
    "    text = re.sub(r\"i'm\", \"I am\", text)\n",
    "    text = re.sub(r\"I\\x89Ûªm\", \"I am\", text)\n",
    "    text = re.sub(r\"I'm\", \"I am\", text)\n",
    "    text = re.sub(r\"Isn't\", \"is not\", text)\n",
    "    text = re.sub(r\"Here's\", \"Here is\", text)\n",
    "    text = re.sub(r\"you've\", \"you have\", text)\n",
    "    text = re.sub(r\"you\\x89Ûªve\", \"you have\", text)\n",
    "    text = re.sub(r\"we're\", \"we are\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"couldn't\", \"could not\", text)\n",
    "    text = re.sub(r\"we've\", \"we have\", text)\n",
    "    text = re.sub(r\"it\\x89Ûªs\", \"it is\", text)\n",
    "    text = re.sub(r\"doesn\\x89Ûªt\", \"does not\", text)\n",
    "    text = re.sub(r\"It\\x89Ûªs\", \"It is\", text)\n",
    "    text = re.sub(r\"Here\\x89Ûªs\", \"Here is\", text)\n",
    "    text = re.sub(r\"who's\", \"who is\", text)\n",
    "    text = re.sub(r\"I\\x89Ûªve\", \"I have\", text)\n",
    "    text = re.sub(r\"y'all\", \"you all\", text)\n",
    "    text = re.sub(r\"can\\x89Ûªt\", \"cannot\", text)\n",
    "    text = re.sub(r\"would've\", \"would have\", text)\n",
    "    text = re.sub(r\"it'll\", \"it will\", text)\n",
    "    text = re.sub(r\"we'll\", \"we will\", text)\n",
    "    text = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", text)\n",
    "    text = re.sub(r\"We've\", \"We have\", text)\n",
    "    text = re.sub(r\"he'll\", \"he will\", text)\n",
    "    text = re.sub(r\"Y'all\", \"You all\", text)\n",
    "    text = re.sub(r\"Weren't\", \"Were not\", text)\n",
    "    text = re.sub(r\"Didn't\", \"Did not\", text)\n",
    "    text = re.sub(r\"they'll\", \"they will\", text)\n",
    "    text = re.sub(r\"they'd\", \"they would\", text)\n",
    "    text = re.sub(r\"DON'T\", \"DO NOT\", text)\n",
    "    text = re.sub(r\"That\\x89Ûªs\", \"That is\", text)\n",
    "    text = re.sub(r\"they've\", \"they have\", text)\n",
    "    text = re.sub(r\"i'd\", \"I would\", text)\n",
    "    text = re.sub(r\"should've\", \"should have\", text)\n",
    "    text = re.sub(r\"You\\x89Ûªre\", \"You are\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"Don\\x89Ûªt\", \"Do not\", text)\n",
    "    text = re.sub(r\"we'd\", \"we would\", text)\n",
    "    text = re.sub(r\"i'll\", \"I will\", text)\n",
    "    text = re.sub(r\"weren't\", \"were not\", text)\n",
    "    text = re.sub(r\"They're\", \"They are\", text)\n",
    "    text = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", text)\n",
    "    text = re.sub(r\"you\\x89Ûªll\", \"you will\", text)\n",
    "    text = re.sub(r\"I\\x89Ûªd\", \"I would\", text)\n",
    "    text = re.sub(r\"let's\", \"let us\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"don't\", \"do not\", text)\n",
    "    text = re.sub(r\"you're\", \"you are\", text)\n",
    "    text = re.sub(r\"i've\", \"I have\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"i'll\", \"I will\", text)\n",
    "    text = re.sub(r\"doesn't\", \"does not\", text)\n",
    "    text = re.sub(r\"i'd\", \"I would\", text)\n",
    "    text = re.sub(r\"didn't\", \"did not\", text)\n",
    "    text = re.sub(r\"ain't\", \"am not\", text)\n",
    "    text = re.sub(r\"you'll\", \"you will\", text)\n",
    "    text = re.sub(r\"I've\", \"I have\", text)\n",
    "    text = re.sub(r\"Don't\", \"do not\", text)\n",
    "    text = re.sub(r\"I'll\", \"I will\", text)\n",
    "    text = re.sub(r\"I'd\", \"I would\", text)\n",
    "    text = re.sub(r\"Let's\", \"Let us\", text)\n",
    "    text = re.sub(r\"you'd\", \"You would\", text)\n",
    "    text = re.sub(r\"It's\", \"It is\", text)\n",
    "    text = re.sub(r\"Ain't\", \"am not\", text)\n",
    "    text = re.sub(r\"Haven't\", \"Have not\", text)\n",
    "    text = re.sub(r\"Could've\", \"Could have\", text)\n",
    "    text = re.sub(r\"youve\", \"you have\", text)  \n",
    "    text = re.sub(r\"donå«t\", \"do not\", text)\n",
    "    \n",
    "    word_tokens = text.split()\n",
    "    output_text = [w for w in word_tokens if not w in STOPWORDS] \n",
    "    text=\" \".join(output_text)\n",
    "    return text\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(preprocess)\n",
    "df_test['text'] = df_test['text'].apply(preprocess)\n",
    "df_train = df_train[df_train[\"text\"]!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4ac0958",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[[\"text\",\"target\"]]\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36e4f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bd6b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lists of lyrics and their labels.\n",
    "texts = df_train.text.values\n",
    "labels = df_train.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "211d3a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification, AdamW\n",
    "\n",
    "tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-discriminator')\n",
    "model = ElectraForSequenceClassification.from_pretrained('google/electra-base-discriminator',num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51cb4379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAE9CAYAAADj+KBFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAc9ElEQVR4nO3de/xldV3v8debm4qCIzBxiEuDSvGwMqQJMXwQQnkBE48hVqZIPKSLJ/FoJyZOSuUxh9NRxI6XeKg5lqGICuSQSghipcgMkNwkEEeBw2VUFNAAkc/5Y31/thnn95s189v7d1nzej4e+/Fb67vW3vuz1/x+897r9v2mqpAkScO0zXwXIEmSJseglyRpwAx6SZIGzKCXJGnADHpJkgbMoJckacC2m+8CJmG33XarZcuWzXcZkiTNmbVr136jqpZu2D7IoF+2bBlr1qyZ7zIkSZozSb62sXYP3UuSNGAGvSRJA2bQS5I0YAa9JEkDZtBLkjRgBr0kSQNm0EuSNGAGvSRJA2bQS5I0YAa9JEkDZtBLkjRgg+zrXgvTshWre623buVRE65EkrYe7tFLkjRgBr0kSQNm0EuSNGAGvSRJA2bQS5I0YAa9JEkDZtBLkjRgBr0kSQM2saBP8r4kdyW5ZqRtlyQXJrmx/XxCa0+Stye5KcmXkhw48pzj2vo3JjluUvVKkjREk9yjfz/w3A3aVgAXVdV+wEVtHuB5wH7tcSLwLui+GACnAk8HDgJOnfpyIEmSNm1iQV9VlwLf2qD5aGBVm14FvHCk/QPV+QKwJMkewHOAC6vqW1V1N3AhP/rlQZIkTWOuz9HvXlW3t+k7gN3b9J7ALSPr3drapmuXJEk9zNvFeFVVQI3r9ZKcmGRNkjXr168f18tKkrSozXXQ39kOydN+3tXabwP2Hllvr9Y2XfuPqKozq2p5VS1funTp2AuXJGkxmuugPx+YunL+OOC8kfaXt6vvDwa+0w7xfwp4dpIntIvwnt3aJElSDxMbjz7JWcBhwG5JbqW7en4lcHaSE4CvAce21S8AjgRuAr4HHA9QVd9K8kbg8rben1fVhhf4SZKkaUws6KvqN6ZZdMRG1i3gVdO8zvuA942xNEmSthr2jCdJ0oAZ9JIkDZhBL0nSgBn0kiQNmEEvSdKAGfSSJA2YQS9J0oAZ9JIkDZhBL0nSgBn0kiQNmEEvSdKAGfSSJA2YQS9J0oAZ9JIkDZhBL0nSgBn0kiQNmEEvSdKAGfSSJA2YQS9J0oAZ9JIkDZhBL0nSgBn0kiQNmEEvSdKAGfSSJA2YQS9J0oAZ9JIkDZhBL0nSgBn0kiQNmEEvSdKAGfSSJA2YQS9J0oAZ9JIkDZhBL0nSgBn0kiQNmEEvSdKAGfSSJA3YdvNdgMZj2YrVvdZbt/KoCVciSVpI3KOXJGnADHpJkgbMoJckacAMekmSBmxegj7Jf09ybZJrkpyV5NFJ9k1yWZKbknw4yQ5t3Ue1+Zva8mXzUbMkSYvRnAd9kj2BVwPLq+pngG2BXwdOA06vqicDdwMntKecANzd2k9v60mSpB7m69D9dsBjkmwH7AjcDhwOnNOWrwJe2KaPbvO05UckydyVKknS4jXnQV9VtwH/B/g6XcB/B1gLfLuqHmqr3Qrs2ab3BG5pz32orb/rhq+b5MQka5KsWb9+/WQ/hCRJi8R8HLp/At1e+r7AjwOPBZ4729etqjOranlVLV+6dOlsX06SpEGYj0P3vwx8tarWV9X3gY8BhwBL2qF8gL2A29r0bcDeAG3544Fvzm3JkiQtTvMR9F8HDk6yYzvXfgRwHXAxcExb5zjgvDZ9fpunLf9MVdUc1itJ0qI1H+foL6O7qO4K4OpWw5nAycBrk9xEdw7+ve0p7wV2be2vBVbMdc2SJC1W8zKoTVWdCpy6QfPNwEEbWfd+4MVzUZckSUNjz3iSJA3YZgV9km2S7DypYiRJ0nhtMuiT/H2SnZM8FrgGuC7J/5h8aZIkabb67NE/paruoeup7h/p7n9/2SSLkiRJ49En6LdPsj1d0J/f7n2XJEmLQJ+g/2tgHV0Pdpcm+Qm6bmglSdIC1yfo/6Gq9qyqI1tHNV8HfnvCdUmSpDHoE/QfHZ1pYf+hyZQjSZLGadoOc5LsD/w08PgkLxpZtDPw6EkXJkmSZm+mnvF+Cng+sAT41ZH2e4FXTrAmSZI0JtMGfVWdB5yX5BlV9fk5rEmSJI1Jn77ub0pyCrBsdP2q8oI8SZIWuD5Bfx7wOeCfgB9MthxJkjROfYJ+x6o6eeKVSJKksetze90nkhw58UokSdLY9Qn6k+jC/v4k9yS5N8k9ky5MkiTN3iYP3VfVTnNRiCRJGr8+w9QmyW8leX2b3zvJQZMvTZIkzVafQ/fvBJ4B/Gabvw94x8QqkiRJY9PnqvunV9WBSa4EqKq7k+ww4bokSdIY9Nmj/36SbYECSLIUeHiiVUmSpLHoE/RvBz4O/FiSNwH/DPzFRKuSJElj0eeq+w8mWQscAQR4YVVdP/HKJEnSrPU5Rw9wJ103uNsBj0lyYFVdMbmyJEnSOGwy6JO8EXgF8BXaefr28/DJlSXNvWUrVvded93KoyZYiSSNT589+mOBJ1XVg5MuRpIkjVefi/GuAZZMuA5JkjQBffbo3wxcmeQa4IGpxqp6wcSqkiRJY9En6FcBpwFX4/3zkiQtKn2C/ntV9faJVyJJksauT9B/LsmbgfN55KF7b6+TJGmB6xP0T2s/Dx5p8/Y6SZIWgT494z1rLgqRJEnj16fDnCXAy4Flo+tX1asnVpUkSRqLPofuLwC+gFfdS5K06PQJ+kdX1WsnXokkSRq7Pj3j/W2SVybZI8kuU4+JVyZJkmatzx79g8BfAv+TRw5q88RJFSVJksajT9C/DnhyVX1j0sVIkqTx6nPo/ibge5MuRJIkjV+fPfrvAlcluZhH9oy3xbfXtVv23gP8DN1pgN8GbgA+THcb3zrg2Kq6O0mAM4Aj6b5wvMJe+SRJ6qdP0J/bHuN0BvDJqjomyQ7AjsApwEVVtTLJCmAFcDLwPGC/9ng68K72U5IkbUKfnvFWtTD+ydZ0Q1V9f0vfMMnjgUOBV7TXfxB4MMnRwGFttVXAJXRBfzTwgaoq4AtJliTZo6pu39IaJEnaWmzyHH2Sw4AbgXcA7wT+Pcmhs3jPfYH1wN8kuTLJe5I8Fth9JLzvAHZv03sCt4w8/9bWtmGdJyZZk2TN+vXrZ1GeJEnD0edivLcAz66qX6qqQ4HnAKfP4j23Aw4E3lVVT6O7BmDF6Apt77028txpVdWZVbW8qpYvXbp0FuVJkjQcfYJ++6q6YWqmqv4d2H4W73krcGtVXdbmz6EL/juT7AHQft7Vlt8G7D3y/L1amyRJ2oQ+Qb+mHV4/rD3eA6zZ0jesqjuAW5L8VGs6AriObrz741rbccB5bfp84OXpHAx8x/PzkiT10+eq+98DXgVM3U53Kd2V77PxB8AH20V+NwPH033pODvJCcDXgGPbuhfQ3Vo3dT//8bN8b0mSthrTBn2SpcDSqroOeGt7kOSngZ3pLqjbIlV1FbB8I4uO2Mi6RfdFQ5IkbaaZDt3/FbDbRtp3obsPXpIkLXAzBf2Tq+rSDRur6nPAUydXkiRJGpeZgn6nGZbN5qp7SZI0R2YK+puSHLlhY5Ln0V1AJ0mSFriZrrp/DbA6ybHA2ta2HHgG8PwJ1yVJksZg2j36qroR+Fngs3Qjyi1r009tneZIkqQFbsb76KvqAeBv5qgWSZI0Zn16xpMkSYtUn57xpBktW7F6vkuQJE1jpp7xLqqqI5KcVlUnz2VR2rr1/eKwbuVRE65Ekha/mfbo90jyi8ALknwIyOjCqrpiopVJkqRZmyno3wC8nm5Y2LdusKyAwydVlOafh+MlaRimDfqqOgc4J8nrq+qNc1iTJEkak01ejFdVb0zyAuDQ1nRJVX1ismVJkqRx2OTtdUneDJwEXNceJyX5i0kXJkmSZq/P7XVHAQdU1cMASVYBVwKnTLIwSZI0e307zFkyMv34CdQhSZImoM8e/ZuBK5NcTHeL3aHAiolWJUmSxqLPxXhnJbkE+IXWdHJV3THRqiRJ0lj06gK3qm4Hzp9wLZIkacwc1EaSpAEz6CVJGrAZD90n2Ra4tqr2n6N6NGF2bStJW5cZ9+ir6gfADUn2maN6JEnSGPW5GO8JwLVJvgh8d6qxql4wsaokSdJY9An610+8CmkLOG69JG1an/voP5vkJ4D9quqfkuwIbDv50iRJ0mz1GdTmlcA5wF+3pj2BcydYkyRJGpM+t9e9CjgEuAegqm4EfmySRUmSpPHoE/QPVNWDUzNJtgNqciVJkqRx6RP0n01yCvCYJL8CfAT4h8mWJUmSxqFP0K8A1gNXA78DXAD8ySSLkiRJ49HnqvuHk6wCLqM7ZH9DVXnoXpKkRWCTQZ/kKODdwFfoxqPfN8nvVNU/Tro4SZI0O306zHkL8KyqugkgyZOA1YBBL0nSAtfnHP29UyHf3AzcO6F6JEnSGE27R5/kRW1yTZILgLPpztG/GLh8DmqTJEmzNNOh+18dmb4T+KU2vR54zMQqkiRJYzNt0FfV8XNZiCRJGr8+V93vC/wBsGx0fYeplSRp4etz1f25wHvpesN7eFxvnGRbYA1wW1U9v32h+BCwK7AWeFlVPZjkUcAHgJ8Hvgm8pKrWjasODV/f4WwlaYj6XHV/f1W9vaourqrPTj3G8N4nAdePzJ8GnF5VTwbuBk5o7ScAd7f209t6kiSphz5Bf0aSU5M8I8mBU4/ZvGmSvYCjgPe0+QCH0w2HC7AKeGGbPrrN05Yf0daXJEmb0OfQ/c8CL6ML4qlD99Xmt9TbgD8CdmrzuwLfrqqH2vytdOPe037eAlBVDyX5Tlv/G7N4f0mStgp9gv7FwBNHh6qdjSTPB+6qqrVJDhvHa7bXPRE4EWCfffYZ18tKkrSo9Tl0fw2wZIzveQjwgiTr6C6+Oxw4A1jSxroH2Au4rU3fBuwN0JY/nu6ivEeoqjOranlVLV+6dOkYy5UkafHqE/RLgC8n+VSS86ceW/qGVfXHVbVXVS0Dfh34TFW9FLgYOKatdhxwXps+v83Tln/G0fMkSeqnz6H7UydeRedk4ENJ/hdwJd0tfbSff5vkJuBbdF8OJElSD33Gox/HrXTTvfYlwCVt+mbgoI2scz/ddQKSJGkz9ekZ7166q+wBdgC2B75bVTtPsjBJkjR7ffbop26Bm7rf/Wjg4EkWJUmSxqPPxXg/VJ1zgedMphxJkjROfQ7dv2hkdhtgOXD/xCqSJElj0+eq+9Fx6R8C1tEdvpckSQtcn3P0jksvSdIiNW3QJ3nDDM+rqnrjBOqRJEljNNMe/Xc30vZYumFjdwUMekmSFrhpg76q3jI1nWQnuvHjj6frn/4t0z1PkiQtHDOeo0+yC/Ba4KV0Y8IfWFV3z0VhkiRp9mY6R/+XwIuAM4Gfrar75qwqSZI0FjN1mPM64MeBPwH+X5J72uPeJPfMTXmSJGk2ZjpHv1m95kmSpIXHMJckacAMekmSBsyglyRpwAx6SZIGzKCXJGnA+oxep3m0bMXq+S5BkrSIuUcvSdKAGfSSJA2YQS9J0oAZ9JIkDZhBL0nSgBn0kiQNmLfXSVug722P61YeNeFKJGlm7tFLkjRgBr0kSQNm0EuSNGAGvSRJA2bQS5I0YAa9JEkDZtBLkjRgBr0kSQNm0EuSNGAGvSRJA2bQS5I0YAa9JEkDZtBLkjRgBr0kSQM258PUJtkb+ACwO1DAmVV1RpJdgA8Dy4B1wLFVdXeSAGcARwLfA15RVVfMdd3j1neYU0mSZmM+xqN/CHhdVV2RZCdgbZILgVcAF1XVyiQrgBXAycDzgP3a4+nAu9rPOeX445KkxWjOD91X1e1Te+RVdS9wPbAncDSwqq22Cnhhmz4a+EB1vgAsSbLH3FYtSdLiNB979D+UZBnwNOAyYPequr0tuoPu0D50XwJuGXnara3tdqStjEeWJG2ueQv6JI8DPgq8pqru6U7Fd6qqktRmvt6JwIkA++yzzzhL3Syee5ckLSTzctV9ku3pQv6DVfWx1nzn1CH59vOu1n4bsPfI0/dqbY9QVWdW1fKqWr506dLJFS9J0iIy50HfrqJ/L3B9Vb11ZNH5wHFt+jjgvJH2l6dzMPCdkUP8kiRpBvNx6P4Q4GXA1Umuam2nACuBs5OcAHwNOLYtu4Du1rqb6G6vO35Oq5UkaRGb86Cvqn8GMs3iIzayfgGvmmhR0oR48Zyk+WbPeJIkDZhBL0nSgBn0kiQN2Lx2mCOpY/8LkibFPXpJkgbMoJckacAMekmSBsyglyRpwAx6SZIGzKCXJGnADHpJkgbMoJckacAMekmSBsyglyRpwAx6SZIGzKCXJGnADHpJkgbMoJckacAMekmSBsyglyRpwAx6SZIGzKCXJGnADHpJkgbMoJckacAMekmSBmy7+S5A0vgtW7G613rrVh414UokzTf36CVJGjCDXpKkATPoJUkaMINekqQBM+glSRowg16SpAHz9jppK+ZteNLwuUcvSdKAGfSSJA2Yh+4lbVLfQ/ybw9MB0txwj16SpAEz6CVJGjCDXpKkATPoJUkasEUT9Emem+SGJDclWTHf9UiStBgsiqvuk2wLvAP4FeBW4PIk51fVdfNbmaQtNe7Oeuz8R9q4RRH0wEHATVV1M0CSDwFHAwa9NHDjvrXPLwTa2iyWoN8TuGVk/lbg6fNUi6StgH0HTM8vS9NbiNtmsQT9JiU5ETixzd6X5IbNePpuwDfGX9VWx+04e27D2Vuw2zCnzXcFvY1lGy6izzsJM27DCW2bn9hY42IJ+tuAvUfm92ptP1RVZwJnbsmLJ1lTVcu3vDyB23Ec3Iaz5zacPbfh7C2kbbhYrrq/HNgvyb5JdgB+HTh/nmuSJGnBWxR79FX1UJL/BnwK2BZ4X1VdO89lSZK04C2KoAeoqguACyb08lt0yF8/wu04e27D2XMbzp7bcPYWzDZMVc13DZIkaUIWyzl6SZK0Bbb6oLdr3c2X5H1J7kpyzUjbLkkuTHJj+/mE+axxoUuyd5KLk1yX5NokJ7V2t2NPSR6d5ItJ/q1twz9r7fsmuaz9TX+4XcCrGSTZNsmVST7R5t2GmynJuiRXJ7kqyZrWtiD+nrfqoB/pWvd5wFOA30jylPmtalF4P/DcDdpWABdV1X7ARW1e03sIeF1VPQU4GHhV+91zO/b3AHB4Vf0ccADw3CQHA6cBp1fVk4G7gRPmr8RF4yTg+pF5t+GWeVZVHTByW92C+HveqoOeka51q+pBYKprXc2gqi4FvrVB89HAqja9CnjhXNa02FTV7VV1RZu+l+4/2T1xO/ZWnfva7PbtUcDhwDmt3W24CUn2Ao4C3tPmg9twXBbE3/PWHvQb61p3z3mqZbHbvapub9N3ALvPZzGLSZJlwNOAy3A7bpZ2yPkq4C7gQuArwLer6qG2in/Tm/Y24I+Ah9v8rrgNt0QBn06ytvXUCgvk73nR3F6nxaOqKom3c/SQ5HHAR4HXVNU93c5Ux+24aVX1A+CAJEuAjwP7z29Fi0uS5wN3VdXaJIfNczmL3TOr6rYkPwZcmOTLowvn8+95a9+j32TXuurtziR7ALSfd81zPQteku3pQv6DVfWx1ux23AJV9W3gYuAZwJIkUzsx/k3P7BDgBUnW0Z26PBw4A7fhZquq29rPu+i+dB7EAvl73tqD3q51x+d84Lg2fRxw3jzWsuC186DvBa6vqreOLHI79pRkaduTJ8ljgF+hu9bhYuCYtprbcAZV9cdVtVdVLaP7/+8zVfVS3IabJcljk+w0NQ08G7iGBfL3vNV3mJPkSLpzVFNd675pfita+JKcBRxGNzrTncCpwLnA2cA+wNeAY6tqwwv21CR5JvA54Gr+89zoKXTn6d2OPSR5Kt0FTtvS7bScXVV/nuSJdHunuwBXAr9VVQ/MX6WLQzt0/4dV9Xy34eZp2+vjbXY74O+r6k1JdmUB/D1v9UEvSdKQbe2H7iVJGjSDXpKkATPoJUkaMINekqQBM+glSRowg14akeS+Ta81q9d/TZIdx/F+SR6V5J/aaFkv2cjyP0zy5bb88iQv39L3mrQkS5L8/gzLf9A+x9Sj9+AgSQ6bGpVtC2ub9vltxLLd2vS/bul7SJNkF7jS3HoN8HfA98bwWk8DqKoDNlyQ5HfpOpA5qHWtuzPwX8fwnpOyBPh94J3TLP+PjX3OhaSqfnG+a5A2xj16aROSPCnJJ9tgFZ9Lsn9rf3+Styf51yQ3JzmmtW+T5J1tb/rCJBckOSbJq4EfBy5OcvHI67+pjan+hSQ/MuhFG9P63CRfaus8tfWn/XfAL7Q93Cdt8LRTgN+rqnsAquqeqlrVXu+IdGOPX53kfUke1drXJXnz1HjaSQ5M8qkkX2lfHKb2bj+b5Lz2mVcmeWm6ceGvnqqj9Vr30XYk4fIkh7T2P23veUl7/qtbvSuBJ7X3/svN+LfZZM3NzklWJ7khybuTbNOe/+wkn09yRZKPpBt7gCTPbf9+VwAvGnm/XZN8Osm1Sd4DZGTZfSPb6JIk57TX+GDSDWKQ5MjWtrb97kyN//5LI0crrkzrZU0ai6ry4cNHewD3baTtImC/Nv10um5CAd4PfITuC/NT6IY8hq7r0Ata+3+hG8/7mLZsHbDbyGsX8Ktt+n8Df7KR9/8r4NQ2fThwVZs+DPjERtbfGbh7ms/3aLoRG3+yzX+AbkCdqdp+r02fDnwJ2AlYCtw58p7fBvYAHkXXB/qftWUnAW9r039PN8gHdL2CXd+m/xT41/bc3YBv0g0vuwy4ZoZ/lx8AV408XrKZNd8PPJGuF70L27/RbsClwGPbeicDbxjZRvvRBfnZU9sZeDvwhjZ9VPv32230d6e933fo+ojfBvg88MyR1923rXfWyOv+A3BIm34csN18/y34GM7DQ/fSDNoe3i8CH8l/jiz3qJFVzq2qh4HrRvbGnwl8pLXfMbr3vhEPAlPnf9fSHW7f0DOBXwOoqs+0vcqdt+gDwU8BX62qf2/zq4BX0XUDDf851sPVwOOq6l7g3iQPpPUrD1xebejNJF8BPj3ynGe16V8GnjKyzXae2lsGVlfXneoDSe6i39CdMx2671PzF6vq5lbzWXTb9H66L2j/0urcgS6U96fbRje29f8OmBp29FDaHn5VrU5y9zQ1fbGqbm3Pv4rui8x9wM1V9dW2zlkjr/svwFuTfBD42NRzpXEw6KWZbUM3NvcB0ywf7f8706wzk+9X1VQ/1D9gDH+T1Z2Tvy/JE6fCbTNMfZ6HeeRne3iktg3bH9jIOtsAB1fV/aMv3gJ19Pnj+Mx9at6wr++i+/e6sKp+Y4MaD5hlPaM1QY/PWFUrk6wGjqT74vGcqvryTM+R+vIcvTSD6s5xfzXJi6EbdS7Jz23iaf8C/Fq6c/W70x3KnXIv3aHlzfE54KXt/Q8DvtHqmsmbgXdM7fkneVy6q+5vAJYleXJb72XAZzeznj4+DfzB1EyP8NyS7bI5Dko3SuU2wEuAfwa+ABwytS3SjUD2k8CX6bbR1HUPo18ELgV+s63/POAJm1HDDcATkyxr8z+8UyLJk6rq6qo6jW5Uzf039wNK0zHopUfaMcmtI4/X0oXsCUn+DbgWOHoTr/FR4FbgOroL5q6gO2cLcCbwyU0czt/QnwI/n+RLdBetHTfz6gC8i26o0cuTXEP3ZeHhtod9PN2piKmR8969GbX09WpgeboLCK8Dfnemlavqm3R7stdMczHeY/LI2+tWbmY9lwP/l24Y268CH6+q9cArgLPatv08sH/bRicCq9vFeKNjiP8ZcGiSa+kO4X+9bwFV9R90dxZ8Mslaui83U78Xr2mf/UvA94F/3MzPJ03L0eukCUjyuKq6L90wlV+ku9DqjvmuS/Nr5PciwDuAG6vq9PmuS8PmOXppMj7RLgTbAXijIa/mlUmOo/u9uBL463muR1sB9+glSRowz9FLkjRgBr0kSQNm0EuSNGAGvSRJA2bQS5I0YAa9JEkD9v8Bwfp7yJk8ow8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to show length of embedding will be helpful to determine maximum length of comments and padding threshold\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_sentence_embeddings_length(text_list, tokenizer):\n",
    "    tokenized_texts = list(map(lambda t: tokenizer.tokenize(t), text_list))\n",
    "    tokenized_texts_len = list(map(lambda t: len(t), tokenized_texts))\n",
    "    fig, ax = plt.subplots(figsize=(8, 5));\n",
    "    ax.hist(tokenized_texts_len, bins=40);\n",
    "    ax.set_xlabel(\"Length of Comment Embeddings\");\n",
    "    ax.set_ylabel(\"Number of Comments\");\n",
    "    return\n",
    "plot_sentence_embeddings_length(texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2440a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=tokenizer.batch_encode_plus(texts,max_length=64,add_special_tokens=True, return_attention_mask=True,padding='max_length',truncation=True)\n",
    "\n",
    "input_ids=indices[\"input_ids\"]\n",
    "attention_masks=indices[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "482ce9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use 80% for training and 20% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=42, test_size=0.2)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b59f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "validation_labels = torch.tensor(validation_labels, dtype=torch.long)\n",
    "train_masks = torch.tensor(train_masks, dtype=torch.long)\n",
    "validation_masks = torch.tensor(validation_masks, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba5fb8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f81ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments1 = df_test.text.values\n",
    "\n",
    "indices1=tokenizer.batch_encode_plus(comments1,max_length=128,add_special_tokens=True, return_attention_mask=True,padding='max_length',truncation=True)\n",
    "input_ids1=indices1[\"input_ids\"]\n",
    "attention_masks1=indices1[\"attention_mask\"]\n",
    "\n",
    "prediction_inputs1= torch.tensor(input_ids1)\n",
    "prediction_masks1 = torch.tensor(attention_masks1)\n",
    "\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size_test = 32\n",
    "\n",
    "# Create the Test DataLoader.\n",
    "prediction_data1 = TensorDataset(prediction_inputs1, prediction_masks1)\n",
    "prediction_sampler1 = SequentialSampler(prediction_data1)\n",
    "prediction_dataloader1 = DataLoader(prediction_data1, sampler=prediction_sampler1, batch_size=batch_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b7e0c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 5\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, \n",
    "                                            num_training_steps = total_steps)\n",
    "# scheduler = StepLR(optimizer, step_size=1, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0af8ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40591772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3fa930e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validation_dataloader, device):\n",
    "    # Validation\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    \n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "\n",
    "    preds=[]\n",
    "    true=[]\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        preds.append(logits)\n",
    "        true.append(label_ids)\n",
    "        # Calculate the accuracy for this batch.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "    \n",
    "    # Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "    flat_predictions = [item for sublist in preds for item in sublist]\n",
    "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "    # Combine the correct labels for each batch into a single list.\n",
    "    flat_true_labels = [item for sublist in true for item in sublist]\n",
    "    \n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(flat_predictions,flat_true_labels))\n",
    "    \n",
    "    return eval_accuracy/nb_eval_steps # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a88753d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, prediction_dataloader1, device):\n",
    "    print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs1)))\n",
    "\n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    predictions = []\n",
    "\n",
    "    # Predict \n",
    "    for batch in prediction_dataloader1:\n",
    "      # Add batch to GPU\n",
    "      batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "      # Unpack the inputs from our dataloader\n",
    "      b_input_ids1, b_input_mask1 = batch\n",
    "\n",
    "      # Telling the model not to compute or store gradients, saving memory and \n",
    "      # speeding up prediction\n",
    "      with torch.no_grad():\n",
    "          # Forward pass, calculate logit predictions\n",
    "          outputs1 = model(b_input_ids1, token_type_ids=None, \n",
    "                          attention_mask=b_input_mask1)\n",
    "\n",
    "      logits1 = outputs1[0]\n",
    "\n",
    "      # Move logits and labels to CPU\n",
    "      logits1 = logits1.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "      # Store predictions and true labels\n",
    "      predictions.append(logits1)\n",
    "\n",
    "    flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "    answer=pd.read_csv('./answer.csv')\n",
    "    ans = answer['target'].values.tolist()\n",
    "\n",
    "    error = 0\n",
    "    for truth, pred in zip(ans, flat_predictions):\n",
    "        error += abs(truth-pred)\n",
    "    accuracy = 1-error/len(ans)\n",
    "    print(f'  Test Accuracy:', accuracy)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a7bb1d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    189.    Elapsed: 0:06:28.\n",
      "  Batch   100  of    189.    Elapsed: 0:13:09.\n",
      "  Batch   150  of    189.    Elapsed: 0:19:55.\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epoch took: 0:25:04\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.50\n",
      "  Validation took: 0:02:05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.71      0.34       272\n",
      "           1       0.88      0.46      0.60      1241\n",
      "\n",
      "    accuracy                           0.50      1513\n",
      "   macro avg       0.55      0.58      0.47      1513\n",
      "weighted avg       0.76      0.50      0.55      1513\n",
      "\n",
      "Predicting labels for 3,263 test sentences...\n",
      "  Test Accuracy: 0.49647563591786703\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    189.    Elapsed: 0:06:40.\n",
      "  Batch   100  of    189.    Elapsed: 0:13:22.\n",
      "  Batch   150  of    189.    Elapsed: 0:20:05.\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epoch took: 0:25:11\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.50\n",
      "  Validation took: 0:02:07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.71      0.34       272\n",
      "           1       0.88      0.46      0.60      1241\n",
      "\n",
      "    accuracy                           0.50      1513\n",
      "   macro avg       0.55      0.58      0.47      1513\n",
      "weighted avg       0.76      0.50      0.55      1513\n",
      "\n",
      "Predicting labels for 3,263 test sentences...\n",
      "  Test Accuracy: 0.49647563591786703\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    189.    Elapsed: 0:06:40.\n",
      "  Batch   100  of    189.    Elapsed: 0:13:21.\n",
      "  Batch   150  of    189.    Elapsed: 0:20:00.\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epoch took: 0:25:17\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.50\n",
      "  Validation took: 0:02:09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.71      0.34       272\n",
      "           1       0.88      0.46      0.60      1241\n",
      "\n",
      "    accuracy                           0.50      1513\n",
      "   macro avg       0.55      0.58      0.47      1513\n",
      "weighted avg       0.76      0.50      0.55      1513\n",
      "\n",
      "Predicting labels for 3,263 test sentences...\n",
      "  Test Accuracy: 0.49647563591786703\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    189.    Elapsed: 0:06:34.\n",
      "  Batch   100  of    189.    Elapsed: 0:13:07.\n",
      "  Batch   150  of    189.    Elapsed: 0:19:25.\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epoch took: 0:24:25\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.50\n",
      "  Validation took: 0:02:01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.71      0.34       272\n",
      "           1       0.88      0.46      0.60      1241\n",
      "\n",
      "    accuracy                           0.50      1513\n",
      "   macro avg       0.55      0.58      0.47      1513\n",
      "weighted avg       0.76      0.50      0.55      1513\n",
      "\n",
      "Predicting labels for 3,263 test sentences...\n",
      "  Test Accuracy: 0.49647563591786703\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "  Batch    50  of    189.    Elapsed: 0:06:23.\n",
      "  Batch   100  of    189.    Elapsed: 0:12:49.\n",
      "  Batch   150  of    189.    Elapsed: 0:19:18.\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epoch took: 0:24:19\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.50\n",
      "  Validation took: 0:02:01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.71      0.34       272\n",
      "           1       0.88      0.46      0.60      1241\n",
      "\n",
      "    accuracy                           0.50      1513\n",
      "   macro avg       0.55      0.58      0.47      1513\n",
      "weighted avg       0.76      0.50      0.55      1513\n",
      "\n",
      "Predicting labels for 3,263 test sentences...\n",
      "  Test Accuracy: 0.49647563591786703\n",
      "\n",
      "Training complete!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# plotting\n",
    "pic_epoch = []\n",
    "pic_val_accu = []\n",
    "pic_test_accu = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    \n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 100 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # `batch` contains three pytorch tensors: [0]: input ids ,[1]: attention masks,[2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Clear any previously calculated gradients.\n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Evaluate the model on this training batch.\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches \n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0. to prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "    \n",
    "    ##################################################################\n",
    "    val_accu = validation(model, validation_dataloader, device)\n",
    "    test_accu = test(model, prediction_dataloader1, device)\n",
    "    pic_epoch.append(epoch_i+1)\n",
    "    pic_val_accu.append(val_accu)\n",
    "    pic_test_accu.append(test_accu)\n",
    "    \n",
    "      \n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "plt.plot(pic_epoch, pic_val_accu, color = 'blue', marker='o', linestyle = '--', label='Validation')\n",
    "plt.plot(pic_epoch, pic_test_accu, color = 'orange', marker='o', linestyle = '-', label='Test')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.xlabel('Epoch', color = 'red')\n",
    "plt.ylabel('Accuracy', color = 'red')\n",
    "plt.title('Accuracy per epoch', color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.8348145878026356 batch = 8, epoch = 2, lr = 2e-5, eps = 1e-8\n",
    "# 0.816426601287159 batch = 8, epoch = 3, lr = 2e-5, eps = 1e-8\n",
    "# 0.8271529267545203 batch = 8, epoch = 4, lr = 2e-5, eps = 1e-8\n",
    "# 0.8277658596383696 batch = 8, epoch = 2, lr = 2e-5, eps = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eeaabeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_sub=pd.read_csv('./dataset/sample_submission.csv')\n",
    "# submit=pd.DataFrame({'id':sample_sub['id'].values.tolist(),'target':flat_predictions})\n",
    "# submit.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96d85cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submit.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
